{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing.drop('medianHouseValue', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = housing['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14448,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6192,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=scaler.transform(X_train),columns = X_train.columns,index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(data=scaler.transform(X_test),columns = X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16086</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.046264</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>0.025873</td>\n",
       "      <td>0.048841</td>\n",
       "      <td>0.353133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8816</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.027417</td>\n",
       "      <td>0.020795</td>\n",
       "      <td>0.012709</td>\n",
       "      <td>0.023187</td>\n",
       "      <td>0.770182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.032326</td>\n",
       "      <td>0.040813</td>\n",
       "      <td>0.041662</td>\n",
       "      <td>0.042592</td>\n",
       "      <td>0.133626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16714</th>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.043212</td>\n",
       "      <td>0.046089</td>\n",
       "      <td>0.032840</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>0.263576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14491</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.088433</td>\n",
       "      <td>0.069367</td>\n",
       "      <td>0.043728</td>\n",
       "      <td>0.072192</td>\n",
       "      <td>0.660046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11807</th>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.103311</td>\n",
       "      <td>0.135009</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>0.141095</td>\n",
       "      <td>0.174632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19109</th>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.057531</td>\n",
       "      <td>0.078057</td>\n",
       "      <td>0.037566</td>\n",
       "      <td>0.077454</td>\n",
       "      <td>0.173377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6926</th>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.050130</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.046179</td>\n",
       "      <td>0.063312</td>\n",
       "      <td>0.205942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.056742</td>\n",
       "      <td>0.053693</td>\n",
       "      <td>0.040577</td>\n",
       "      <td>0.058214</td>\n",
       "      <td>0.352374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11961</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.497910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.068238</td>\n",
       "      <td>0.099472</td>\n",
       "      <td>0.037881</td>\n",
       "      <td>0.098339</td>\n",
       "      <td>0.191473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8128</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.138893</td>\n",
       "      <td>0.196151</td>\n",
       "      <td>0.105276</td>\n",
       "      <td>0.193718</td>\n",
       "      <td>0.188487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.047459</td>\n",
       "      <td>0.054159</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.053938</td>\n",
       "      <td>0.184928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>0.033985</td>\n",
       "      <td>0.019676</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.197204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15832</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.078833</td>\n",
       "      <td>0.029269</td>\n",
       "      <td>0.074823</td>\n",
       "      <td>0.296182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19748</th>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.019330</td>\n",
       "      <td>0.021260</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.022694</td>\n",
       "      <td>0.261500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>0.020484</td>\n",
       "      <td>0.022372</td>\n",
       "      <td>0.026476</td>\n",
       "      <td>0.148598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14477</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.065899</td>\n",
       "      <td>0.080695</td>\n",
       "      <td>0.031439</td>\n",
       "      <td>0.074823</td>\n",
       "      <td>0.255624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9178</th>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>0.132061</td>\n",
       "      <td>0.046879</td>\n",
       "      <td>0.097352</td>\n",
       "      <td>0.235300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.059260</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>0.026538</td>\n",
       "      <td>0.053281</td>\n",
       "      <td>0.469180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12624</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.084999</td>\n",
       "      <td>0.123991</td>\n",
       "      <td>0.046844</td>\n",
       "      <td>0.110015</td>\n",
       "      <td>0.215149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17825</th>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.171652</td>\n",
       "      <td>0.244258</td>\n",
       "      <td>0.148339</td>\n",
       "      <td>0.236310</td>\n",
       "      <td>0.333795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18005</th>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.102701</td>\n",
       "      <td>0.130664</td>\n",
       "      <td>0.076252</td>\n",
       "      <td>0.138464</td>\n",
       "      <td>0.244162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.044280</td>\n",
       "      <td>0.056642</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.043249</td>\n",
       "      <td>0.195818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5816</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.059464</td>\n",
       "      <td>0.119801</td>\n",
       "      <td>0.077828</td>\n",
       "      <td>0.123828</td>\n",
       "      <td>0.140812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8585</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.054046</td>\n",
       "      <td>0.048572</td>\n",
       "      <td>0.028148</td>\n",
       "      <td>0.050156</td>\n",
       "      <td>0.528248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19437</th>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.083244</td>\n",
       "      <td>0.117784</td>\n",
       "      <td>0.053741</td>\n",
       "      <td>0.115770</td>\n",
       "      <td>0.136557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.039572</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.039796</td>\n",
       "      <td>0.073399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14818</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.097295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12015</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.120530</td>\n",
       "      <td>0.129423</td>\n",
       "      <td>0.101530</td>\n",
       "      <td>0.130735</td>\n",
       "      <td>0.267058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.032097</td>\n",
       "      <td>0.042210</td>\n",
       "      <td>0.021286</td>\n",
       "      <td>0.042592</td>\n",
       "      <td>0.140350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093418</td>\n",
       "      <td>0.100559</td>\n",
       "      <td>0.054266</td>\n",
       "      <td>0.104917</td>\n",
       "      <td>0.289003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.042957</td>\n",
       "      <td>0.047641</td>\n",
       "      <td>0.027623</td>\n",
       "      <td>0.042921</td>\n",
       "      <td>0.149301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046213</td>\n",
       "      <td>0.071850</td>\n",
       "      <td>0.037286</td>\n",
       "      <td>0.069561</td>\n",
       "      <td>0.215521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.021084</td>\n",
       "      <td>0.035692</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.198280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20237</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040058</td>\n",
       "      <td>0.053073</td>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.054925</td>\n",
       "      <td>0.213059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9421</th>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.030037</td>\n",
       "      <td>0.030261</td>\n",
       "      <td>0.021881</td>\n",
       "      <td>0.033547</td>\n",
       "      <td>0.224142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.018058</td>\n",
       "      <td>0.022967</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.220349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15571</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.053029</td>\n",
       "      <td>0.054624</td>\n",
       "      <td>0.034625</td>\n",
       "      <td>0.053938</td>\n",
       "      <td>0.275865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.107813</td>\n",
       "      <td>0.128957</td>\n",
       "      <td>0.067430</td>\n",
       "      <td>0.121855</td>\n",
       "      <td>0.213714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.119767</td>\n",
       "      <td>0.102110</td>\n",
       "      <td>0.073032</td>\n",
       "      <td>0.101957</td>\n",
       "      <td>0.539372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.045501</td>\n",
       "      <td>0.080230</td>\n",
       "      <td>0.035115</td>\n",
       "      <td>0.080579</td>\n",
       "      <td>0.208135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15242</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.125235</td>\n",
       "      <td>0.116077</td>\n",
       "      <td>0.051640</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>0.480828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.035124</td>\n",
       "      <td>0.053693</td>\n",
       "      <td>0.025067</td>\n",
       "      <td>0.048512</td>\n",
       "      <td>0.076999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.013912</td>\n",
       "      <td>0.016139</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.209487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.046747</td>\n",
       "      <td>0.054935</td>\n",
       "      <td>0.044988</td>\n",
       "      <td>0.055419</td>\n",
       "      <td>0.255638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12985</th>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.074088</td>\n",
       "      <td>0.076195</td>\n",
       "      <td>0.045128</td>\n",
       "      <td>0.074494</td>\n",
       "      <td>0.194404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8107</th>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.043296</td>\n",
       "      <td>0.034345</td>\n",
       "      <td>0.049498</td>\n",
       "      <td>0.258624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13390</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.019126</td>\n",
       "      <td>0.030881</td>\n",
       "      <td>0.026013</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.100219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17132</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.141869</td>\n",
       "      <td>0.311608</td>\n",
       "      <td>0.145713</td>\n",
       "      <td>0.289755</td>\n",
       "      <td>0.133626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.079582</td>\n",
       "      <td>0.096679</td>\n",
       "      <td>0.055596</td>\n",
       "      <td>0.093241</td>\n",
       "      <td>0.141088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.095096</td>\n",
       "      <td>0.077592</td>\n",
       "      <td>0.046774</td>\n",
       "      <td>0.081894</td>\n",
       "      <td>0.428008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19718</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.097080</td>\n",
       "      <td>0.108783</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.108041</td>\n",
       "      <td>0.134240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.017702</td>\n",
       "      <td>0.035847</td>\n",
       "      <td>0.036516</td>\n",
       "      <td>0.037329</td>\n",
       "      <td>0.119702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9380</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.063330</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.575075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.086118</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.059658</td>\n",
       "      <td>0.094392</td>\n",
       "      <td>0.216631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12815</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.035429</td>\n",
       "      <td>0.057728</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>0.052787</td>\n",
       "      <td>0.149970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12139</th>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.031037</td>\n",
       "      <td>0.021111</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>0.159963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16208</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>0.058054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.147083</td>\n",
       "      <td>0.213842</td>\n",
       "      <td>0.103981</td>\n",
       "      <td>0.215590</td>\n",
       "      <td>0.190963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "16086          0.686275    0.046264       0.045158    0.025873    0.048841   \n",
       "8816           0.705882    0.027417       0.020795    0.012709    0.023187   \n",
       "7175           0.901961    0.032326       0.040813    0.041662    0.042592   \n",
       "16714          0.313725    0.043212       0.046089    0.032840    0.048018   \n",
       "14491          0.411765    0.088433       0.069367    0.043728    0.072192   \n",
       "11807          0.392157    0.103311       0.135009    0.064559    0.141095   \n",
       "19109          0.862745    0.057531       0.078057    0.037566    0.077454   \n",
       "6926           0.607843    0.050130       0.062073    0.046179    0.063312   \n",
       "11649          0.450980    0.056742       0.053693    0.040577    0.058214   \n",
       "11961          0.058824    0.001984       0.001397    0.001821    0.001973   \n",
       "3859           0.549020    0.068238       0.099472    0.037881    0.098339   \n",
       "8128           0.470588    0.138893       0.196151    0.105276    0.193718   \n",
       "2335           0.529412    0.047459       0.054159    0.031334    0.053938   \n",
       "1829           0.411765    0.028409       0.033985    0.019676    0.032560   \n",
       "15832          1.000000    0.058065       0.078833    0.029269    0.074823   \n",
       "19748          0.313725    0.019330       0.021260    0.011168    0.022694   \n",
       "5562           0.784314    0.015718       0.020484    0.022372    0.026476   \n",
       "14477          0.274510    0.065899       0.080695    0.031439    0.074823   \n",
       "9178           0.137255    0.097589       0.132061    0.046879    0.097352   \n",
       "5268           0.450980    0.059260       0.054004    0.026538    0.053281   \n",
       "12624          0.078431    0.084999       0.123991    0.046844    0.110015   \n",
       "17825          0.156863    0.171652       0.244258    0.148339    0.236310   \n",
       "18005          0.431373    0.102701       0.130664    0.076252    0.138464   \n",
       "9982           0.274510    0.044280       0.056642    0.022827    0.043249   \n",
       "5816           0.411765    0.059464       0.119801    0.077828    0.123828   \n",
       "8585           0.686275    0.054046       0.048572    0.028148    0.050156   \n",
       "19437          0.372549    0.083244       0.117784    0.053741    0.115770   \n",
       "2405           0.274510    0.027163       0.039572    0.037356    0.039796   \n",
       "14818          0.686275    0.000610       0.002017    0.001926    0.003618   \n",
       "12015          0.352941    0.120530       0.129423    0.101530    0.130735   \n",
       "...                 ...         ...            ...         ...         ...   \n",
       "10042          0.823529    0.032097       0.042210    0.021286    0.042592   \n",
       "9346           1.000000    0.093418       0.100559    0.054266    0.104917   \n",
       "9776           0.627451    0.042957       0.047641    0.027623    0.042921   \n",
       "8730           1.000000    0.046213       0.071850    0.037286    0.069561   \n",
       "1545           0.137255    0.021084       0.035692    0.014039    0.036672   \n",
       "20237          1.000000    0.040058       0.053073    0.029164    0.054925   \n",
       "9421           0.725490    0.030037       0.030261    0.021881    0.033547   \n",
       "3673           0.764706    0.018058       0.022967    0.018555    0.025325   \n",
       "15571          0.333333    0.053029       0.054624    0.034625    0.053938   \n",
       "3108           0.156863    0.107813       0.128957    0.067430    0.121855   \n",
       "1647           0.215686    0.119767       0.102110    0.073032    0.101957   \n",
       "14693          0.294118    0.045501       0.080230    0.035115    0.080579   \n",
       "15242          0.176471    0.125235       0.116077    0.051640    0.104095   \n",
       "3321           0.313725    0.035124       0.053693    0.025067    0.048512   \n",
       "1095           0.725490    0.013912       0.016139    0.009523    0.015294   \n",
       "1356           0.294118    0.046747       0.054935    0.044988    0.055419   \n",
       "12985          0.607843    0.074088       0.076195    0.045128    0.074494   \n",
       "8107           0.843137    0.035226       0.043296    0.034345    0.049498   \n",
       "13390          0.509804    0.019126       0.030881    0.026013    0.030258   \n",
       "17132          0.509804    0.141869       0.311608    0.145713    0.289755   \n",
       "3275           0.725490    0.079582       0.096679    0.055596    0.093241   \n",
       "1493           0.431373    0.095096       0.077592    0.046774    0.081894   \n",
       "19718          0.470588    0.097080       0.108783    0.069320    0.108041   \n",
       "4889           0.745098    0.017702       0.035847    0.036516    0.037329   \n",
       "9380           0.666667    0.063330       0.063315    0.028323    0.061174   \n",
       "1263           0.352941    0.086118       0.092800    0.059658    0.094392   \n",
       "12815          0.078431    0.035429       0.057728    0.022232    0.052787   \n",
       "12139          0.137255    0.026171       0.031037    0.021111    0.029272   \n",
       "16208          0.764706    0.011445       0.016760    0.014319    0.015787   \n",
       "571            0.588235    0.147083       0.213842    0.103981    0.215590   \n",
       "\n",
       "       medianIncome  \n",
       "16086      0.353133  \n",
       "8816       0.770182  \n",
       "7175       0.133626  \n",
       "16714      0.263576  \n",
       "14491      0.660046  \n",
       "11807      0.174632  \n",
       "19109      0.173377  \n",
       "6926       0.205942  \n",
       "11649      0.352374  \n",
       "11961      0.497910  \n",
       "3859       0.191473  \n",
       "8128       0.188487  \n",
       "2335       0.184928  \n",
       "1829       0.197204  \n",
       "15832      0.296182  \n",
       "19748      0.261500  \n",
       "5562       0.148598  \n",
       "14477      0.255624  \n",
       "9178       0.235300  \n",
       "5268       0.469180  \n",
       "12624      0.215149  \n",
       "17825      0.333795  \n",
       "18005      0.244162  \n",
       "9982       0.195818  \n",
       "5816       0.140812  \n",
       "8585       0.528248  \n",
       "19437      0.136557  \n",
       "2405       0.073399  \n",
       "14818      0.097295  \n",
       "12015      0.267058  \n",
       "...             ...  \n",
       "10042      0.140350  \n",
       "9346       0.289003  \n",
       "9776       0.149301  \n",
       "8730       0.215521  \n",
       "1545       0.198280  \n",
       "20237      0.213059  \n",
       "9421       0.224142  \n",
       "3673       0.220349  \n",
       "15571      0.275865  \n",
       "3108       0.213714  \n",
       "1647       0.539372  \n",
       "14693      0.208135  \n",
       "15242      0.480828  \n",
       "3321       0.076999  \n",
       "1095       0.209487  \n",
       "1356       0.255638  \n",
       "12985      0.194404  \n",
       "8107       0.258624  \n",
       "13390      0.100219  \n",
       "17132      0.133626  \n",
       "3275       0.141088  \n",
       "1493       0.428008  \n",
       "19718      0.134240  \n",
       "4889       0.119702  \n",
       "9380       0.575075  \n",
       "1263       0.216631  \n",
       "12815      0.149970  \n",
       "12139      0.159963  \n",
       "16208      0.058054  \n",
       "571        0.190963  \n",
       "\n",
       "[6192 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "population = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [age, rooms, bedrooms, population, households, income]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train ,batch_size=10,num_epochs=1000,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp8uwnz2sd\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Temp\\\\tmp8uwnz2sd', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002A29BB0ABE0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp8uwnz2sd\\model.ckpt.\n",
      "INFO:tensorflow:loss = 849599000000.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 189.813\n",
      "INFO:tensorflow:loss = 347749880000.0, step = 101 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.675\n",
      "INFO:tensorflow:loss = 465356820000.0, step = 201 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.056\n",
      "INFO:tensorflow:loss = 500800320000.0, step = 301 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.801\n",
      "INFO:tensorflow:loss = 601799100000.0, step = 401 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.368\n",
      "INFO:tensorflow:loss = 632739600000.0, step = 501 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.207\n",
      "INFO:tensorflow:loss = 418787620000.0, step = 601 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.945\n",
      "INFO:tensorflow:loss = 442109530000.0, step = 701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.069\n",
      "INFO:tensorflow:loss = 978679600000.0, step = 801 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.204\n",
      "INFO:tensorflow:loss = 490587500000.0, step = 901 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.802\n",
      "INFO:tensorflow:loss = 555958670000.0, step = 1001 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.85\n",
      "INFO:tensorflow:loss = 665368000000.0, step = 1101 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 469308080000.0, step = 1201 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.623\n",
      "INFO:tensorflow:loss = 730948200000.0, step = 1301 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.67\n",
      "INFO:tensorflow:loss = 376603800000.0, step = 1401 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.631\n",
      "INFO:tensorflow:loss = 623367750000.0, step = 1501 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.75\n",
      "INFO:tensorflow:loss = 327135920000.0, step = 1601 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.059\n",
      "INFO:tensorflow:loss = 358365630000.0, step = 1701 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.708\n",
      "INFO:tensorflow:loss = 319786350000.0, step = 1801 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.366\n",
      "INFO:tensorflow:loss = 557177960000.0, step = 1901 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.254\n",
      "INFO:tensorflow:loss = 499219230000.0, step = 2001 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.291\n",
      "INFO:tensorflow:loss = 292812060000.0, step = 2101 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.632\n",
      "INFO:tensorflow:loss = 377138500000.0, step = 2201 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.206\n",
      "INFO:tensorflow:loss = 102812250000.0, step = 2301 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.661\n",
      "INFO:tensorflow:loss = 475154220000.0, step = 2401 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.371\n",
      "INFO:tensorflow:loss = 248055600000.0, step = 2501 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.85\n",
      "INFO:tensorflow:loss = 305645500000.0, step = 2601 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.946\n",
      "INFO:tensorflow:loss = 243411680000.0, step = 2701 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.302\n",
      "INFO:tensorflow:loss = 318052630000.0, step = 2801 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.61\n",
      "INFO:tensorflow:loss = 312499340000.0, step = 2901 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.333\n",
      "INFO:tensorflow:loss = 55133225000.0, step = 3001 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.631\n",
      "INFO:tensorflow:loss = 393033450000.0, step = 3101 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.36\n",
      "INFO:tensorflow:loss = 470435170000.0, step = 3201 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.368\n",
      "INFO:tensorflow:loss = 170095430000.0, step = 3301 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.208\n",
      "INFO:tensorflow:loss = 325622800000.0, step = 3401 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.944\n",
      "INFO:tensorflow:loss = 112371550000.0, step = 3501 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.534\n",
      "INFO:tensorflow:loss = 207650000000.0, step = 3601 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.378\n",
      "INFO:tensorflow:loss = 226121250000.0, step = 3701 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.95\n",
      "INFO:tensorflow:loss = 272835890000.0, step = 3801 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.145\n",
      "INFO:tensorflow:loss = 196385080000.0, step = 3901 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.044\n",
      "INFO:tensorflow:loss = 71290175000.0, step = 4001 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.212\n",
      "INFO:tensorflow:loss = 204416300000.0, step = 4101 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.133\n",
      "INFO:tensorflow:loss = 54044144000.0, step = 4201 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.544\n",
      "INFO:tensorflow:loss = 240230680000.0, step = 4301 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.608\n",
      "INFO:tensorflow:loss = 219477080000.0, step = 4401 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.946\n",
      "INFO:tensorflow:loss = 270569570000.0, step = 4501 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.534\n",
      "INFO:tensorflow:loss = 39509643000.0, step = 4601 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.632\n",
      "INFO:tensorflow:loss = 139977980000.0, step = 4701 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.342\n",
      "INFO:tensorflow:loss = 197084120000.0, step = 4801 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.07\n",
      "INFO:tensorflow:loss = 118442210000.0, step = 4901 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.701\n",
      "INFO:tensorflow:loss = 118237890000.0, step = 5001 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.011\n",
      "INFO:tensorflow:loss = 71920350000.0, step = 5101 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.133\n",
      "INFO:tensorflow:loss = 212954220000.0, step = 5201 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.286\n",
      "INFO:tensorflow:loss = 206313360000.0, step = 5301 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.329\n",
      "INFO:tensorflow:loss = 42228376000.0, step = 5401 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.291\n",
      "INFO:tensorflow:loss = 136903790000.0, step = 5501 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.943\n",
      "INFO:tensorflow:loss = 125695255000.0, step = 5601 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.205\n",
      "INFO:tensorflow:loss = 98173680000.0, step = 5701 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.942\n",
      "INFO:tensorflow:loss = 81952180000.0, step = 5801 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.206\n",
      "INFO:tensorflow:loss = 46119650000.0, step = 5901 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.799\n",
      "INFO:tensorflow:loss = 101201355000.0, step = 6001 (0.262 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 401.071\n",
      "INFO:tensorflow:loss = 173024080000.0, step = 6101 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.068\n",
      "INFO:tensorflow:loss = 54911830000.0, step = 6201 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.671\n",
      "INFO:tensorflow:loss = 137005556000.0, step = 6301 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.534\n",
      "INFO:tensorflow:loss = 154204370000.0, step = 6401 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.382\n",
      "INFO:tensorflow:loss = 86760810000.0, step = 6501 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.931\n",
      "INFO:tensorflow:loss = 190822190000.0, step = 6601 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.536\n",
      "INFO:tensorflow:loss = 77833600000.0, step = 6701 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.067\n",
      "INFO:tensorflow:loss = 238192690000.0, step = 6801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.946\n",
      "INFO:tensorflow:loss = 39725785000.0, step = 6901 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.53\n",
      "INFO:tensorflow:loss = 110794375000.0, step = 7001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.495\n",
      "INFO:tensorflow:loss = 133091920000.0, step = 7101 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.622\n",
      "INFO:tensorflow:loss = 104975270000.0, step = 7201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.045\n",
      "INFO:tensorflow:loss = 134751730000.0, step = 7301 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.058\n",
      "INFO:tensorflow:loss = 81697660000.0, step = 7401 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.944\n",
      "INFO:tensorflow:loss = 35191490000.0, step = 7501 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.132\n",
      "INFO:tensorflow:loss = 85489830000.0, step = 7601 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.643\n",
      "INFO:tensorflow:loss = 125518110000.0, step = 7701 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.367\n",
      "INFO:tensorflow:loss = 91626840000.0, step = 7801 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.333\n",
      "INFO:tensorflow:loss = 88393310000.0, step = 7901 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.305\n",
      "INFO:tensorflow:loss = 149925360000.0, step = 8001 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.533\n",
      "INFO:tensorflow:loss = 149412070000.0, step = 8101 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.468\n",
      "INFO:tensorflow:loss = 73928930000.0, step = 8201 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.287\n",
      "INFO:tensorflow:loss = 40595358000.0, step = 8301 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.073\n",
      "INFO:tensorflow:loss = 189372660000.0, step = 8401 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.145\n",
      "INFO:tensorflow:loss = 170775350000.0, step = 8501 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.381\n",
      "INFO:tensorflow:loss = 125887030000.0, step = 8601 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.059\n",
      "INFO:tensorflow:loss = 183062170000.0, step = 8701 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.533\n",
      "INFO:tensorflow:loss = 83239910000.0, step = 8801 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.943\n",
      "INFO:tensorflow:loss = 185342510000.0, step = 8901 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.253\n",
      "INFO:tensorflow:loss = 180460830000.0, step = 9001 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.314\n",
      "INFO:tensorflow:loss = 57482703000.0, step = 9101 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.623\n",
      "INFO:tensorflow:loss = 64586500000.0, step = 9201 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.67\n",
      "INFO:tensorflow:loss = 133519520000.0, step = 9301 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.369\n",
      "INFO:tensorflow:loss = 42898350000.0, step = 9401 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.205\n",
      "INFO:tensorflow:loss = 63917703000.0, step = 9501 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.365\n",
      "INFO:tensorflow:loss = 36640050000.0, step = 9601 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.704\n",
      "INFO:tensorflow:loss = 111444410000.0, step = 9701 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.381\n",
      "INFO:tensorflow:loss = 130416060000.0, step = 9801 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.069\n",
      "INFO:tensorflow:loss = 72960550000.0, step = 9901 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.068\n",
      "INFO:tensorflow:loss = 44313100000.0, step = 10001 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.29\n",
      "INFO:tensorflow:loss = 36627560000.0, step = 10101 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.39\n",
      "INFO:tensorflow:loss = 135507710000.0, step = 10201 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.851\n",
      "INFO:tensorflow:loss = 242200660000.0, step = 10301 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.561\n",
      "INFO:tensorflow:loss = 125917540000.0, step = 10401 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.28\n",
      "INFO:tensorflow:loss = 161660080000.0, step = 10501 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.668\n",
      "INFO:tensorflow:loss = 143807330000.0, step = 10601 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.091\n",
      "INFO:tensorflow:loss = 149938910000.0, step = 10701 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.181\n",
      "INFO:tensorflow:loss = 35825066000.0, step = 10801 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.371\n",
      "INFO:tensorflow:loss = 97164870000.0, step = 10901 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.335\n",
      "INFO:tensorflow:loss = 182147550000.0, step = 11001 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.115\n",
      "INFO:tensorflow:loss = 104136050000.0, step = 11101 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.265\n",
      "INFO:tensorflow:loss = 49842060000.0, step = 11201 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.569\n",
      "INFO:tensorflow:loss = 35008463000.0, step = 11301 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.944\n",
      "INFO:tensorflow:loss = 185781190000.0, step = 11401 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.674\n",
      "INFO:tensorflow:loss = 106892550000.0, step = 11501 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.96\n",
      "INFO:tensorflow:loss = 39127590000.0, step = 11601 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.153\n",
      "INFO:tensorflow:loss = 67877216000.0, step = 11701 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.85\n",
      "INFO:tensorflow:loss = 90662950000.0, step = 11801 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.048\n",
      "INFO:tensorflow:loss = 50532737000.0, step = 11901 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.792\n",
      "INFO:tensorflow:loss = 34420230000.0, step = 12001 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.917\n",
      "INFO:tensorflow:loss = 149952970000.0, step = 12101 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.368\n",
      "INFO:tensorflow:loss = 40337334000.0, step = 12201 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.944\n",
      "INFO:tensorflow:loss = 46183444000.0, step = 12301 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.631\n",
      "INFO:tensorflow:loss = 58300957000.0, step = 12401 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.749\n",
      "INFO:tensorflow:loss = 84893870000.0, step = 12501 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.927\n",
      "INFO:tensorflow:loss = 105920270000.0, step = 12601 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.78\n",
      "INFO:tensorflow:loss = 122046170000.0, step = 12701 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.288\n",
      "INFO:tensorflow:loss = 47108612000.0, step = 12801 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.701\n",
      "INFO:tensorflow:loss = 148603800000.0, step = 12901 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.187\n",
      "INFO:tensorflow:loss = 252426130000.0, step = 13001 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.496\n",
      "INFO:tensorflow:loss = 80045770000.0, step = 13101 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.617\n",
      "INFO:tensorflow:loss = 42555306000.0, step = 13201 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.631\n",
      "INFO:tensorflow:loss = 195867460000.0, step = 13301 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.166\n",
      "INFO:tensorflow:loss = 106866860000.0, step = 13401 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.591\n",
      "INFO:tensorflow:loss = 197072030000.0, step = 13501 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.742\n",
      "INFO:tensorflow:loss = 49573300000.0, step = 13601 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.096\n",
      "INFO:tensorflow:loss = 160711950000.0, step = 13701 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.625\n",
      "INFO:tensorflow:loss = 52319584000.0, step = 13801 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.86\n",
      "INFO:tensorflow:loss = 66333240000.0, step = 13901 (0.233 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 405.942\n",
      "INFO:tensorflow:loss = 79122014000.0, step = 14001 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.28\n",
      "INFO:tensorflow:loss = 83332230000.0, step = 14101 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.151\n",
      "INFO:tensorflow:loss = 92551905000.0, step = 14201 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.323\n",
      "INFO:tensorflow:loss = 172834100000.0, step = 14301 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.299\n",
      "INFO:tensorflow:loss = 109611420000.0, step = 14401 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.3\n",
      "INFO:tensorflow:loss = 25175658000.0, step = 14501 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.022\n",
      "INFO:tensorflow:loss = 71296650000.0, step = 14601 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.482\n",
      "INFO:tensorflow:loss = 56654660000.0, step = 14701 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.558\n",
      "INFO:tensorflow:loss = 125197990000.0, step = 14801 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.339\n",
      "INFO:tensorflow:loss = 131023910000.0, step = 14901 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.567\n",
      "INFO:tensorflow:loss = 154260880000.0, step = 15001 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.341\n",
      "INFO:tensorflow:loss = 217042120000.0, step = 15101 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.271\n",
      "INFO:tensorflow:loss = 48196952000.0, step = 15201 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.811\n",
      "INFO:tensorflow:loss = 75453020000.0, step = 15301 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.348\n",
      "INFO:tensorflow:loss = 121881050000.0, step = 15401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.124\n",
      "INFO:tensorflow:loss = 166166200000.0, step = 15501 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.9\n",
      "INFO:tensorflow:loss = 218352100000.0, step = 15601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.054\n",
      "INFO:tensorflow:loss = 94664340000.0, step = 15701 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.66\n",
      "INFO:tensorflow:loss = 166909760000.0, step = 15801 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.754\n",
      "INFO:tensorflow:loss = 161725070000.0, step = 15901 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.936\n",
      "INFO:tensorflow:loss = 112688560000.0, step = 16001 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.19\n",
      "INFO:tensorflow:loss = 195065460000.0, step = 16101 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.888\n",
      "INFO:tensorflow:loss = 138906140000.0, step = 16201 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.558\n",
      "INFO:tensorflow:loss = 90515180000.0, step = 16301 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.595\n",
      "INFO:tensorflow:loss = 87665460000.0, step = 16401 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.922\n",
      "INFO:tensorflow:loss = 148676080000.0, step = 16501 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.955\n",
      "INFO:tensorflow:loss = 94886265000.0, step = 16601 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.132\n",
      "INFO:tensorflow:loss = 63126847000.0, step = 16701 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.278\n",
      "INFO:tensorflow:loss = 117019280000.0, step = 16801 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.676\n",
      "INFO:tensorflow:loss = 112677020000.0, step = 16901 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.124\n",
      "INFO:tensorflow:loss = 94859000000.0, step = 17001 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.131\n",
      "INFO:tensorflow:loss = 52746030000.0, step = 17101 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.328\n",
      "INFO:tensorflow:loss = 79169070000.0, step = 17201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.861\n",
      "INFO:tensorflow:loss = 97138600000.0, step = 17301 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.635\n",
      "INFO:tensorflow:loss = 116190760000.0, step = 17401 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.123\n",
      "INFO:tensorflow:loss = 140878700000.0, step = 17501 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.905\n",
      "INFO:tensorflow:loss = 153160910000.0, step = 17601 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.462\n",
      "INFO:tensorflow:loss = 123563700000.0, step = 17701 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.012\n",
      "INFO:tensorflow:loss = 96661070000.0, step = 17801 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.21\n",
      "INFO:tensorflow:loss = 90007830000.0, step = 17901 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.752\n",
      "INFO:tensorflow:loss = 47889842000.0, step = 18001 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.885\n",
      "INFO:tensorflow:loss = 91115700000.0, step = 18101 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.743\n",
      "INFO:tensorflow:loss = 27048024000.0, step = 18201 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.942\n",
      "INFO:tensorflow:loss = 72369320000.0, step = 18301 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.828\n",
      "INFO:tensorflow:loss = 162950140000.0, step = 18401 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.303\n",
      "INFO:tensorflow:loss = 117887730000.0, step = 18501 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.784\n",
      "INFO:tensorflow:loss = 74679200000.0, step = 18601 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.245\n",
      "INFO:tensorflow:loss = 130059680000.0, step = 18701 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.31\n",
      "INFO:tensorflow:loss = 128802490000.0, step = 18801 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.316\n",
      "INFO:tensorflow:loss = 43768590000.0, step = 18901 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.822\n",
      "INFO:tensorflow:loss = 88088830000.0, step = 19001 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.7\n",
      "INFO:tensorflow:loss = 140665370000.0, step = 19101 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.478\n",
      "INFO:tensorflow:loss = 79410690000.0, step = 19201 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.445\n",
      "INFO:tensorflow:loss = 136822000000.0, step = 19301 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.474\n",
      "INFO:tensorflow:loss = 92017115000.0, step = 19401 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.602\n",
      "INFO:tensorflow:loss = 21535818000.0, step = 19501 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.466\n",
      "INFO:tensorflow:loss = 84541410000.0, step = 19601 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.053\n",
      "INFO:tensorflow:loss = 56060838000.0, step = 19701 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.304\n",
      "INFO:tensorflow:loss = 50202630000.0, step = 19801 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.838\n",
      "INFO:tensorflow:loss = 74699980000.0, step = 19901 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.832\n",
      "INFO:tensorflow:loss = 139114170000.0, step = 20001 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.058\n",
      "INFO:tensorflow:loss = 83793210000.0, step = 20101 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.563\n",
      "INFO:tensorflow:loss = 145572660000.0, step = 20201 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.177\n",
      "INFO:tensorflow:loss = 93887790000.0, step = 20301 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.473\n",
      "INFO:tensorflow:loss = 76866590000.0, step = 20401 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.239\n",
      "INFO:tensorflow:loss = 62297630000.0, step = 20501 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.465\n",
      "INFO:tensorflow:loss = 82894220000.0, step = 20601 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.323\n",
      "INFO:tensorflow:loss = 91365830000.0, step = 20701 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.413\n",
      "INFO:tensorflow:loss = 309713240000.0, step = 20801 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.125\n",
      "INFO:tensorflow:loss = 112889590000.0, step = 20901 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.727\n",
      "INFO:tensorflow:loss = 155864170000.0, step = 21001 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.945\n",
      "INFO:tensorflow:loss = 135532675000.0, step = 21101 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.276\n",
      "INFO:tensorflow:loss = 88838005000.0, step = 21201 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.254\n",
      "INFO:tensorflow:loss = 48703926000.0, step = 21301 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.904\n",
      "INFO:tensorflow:loss = 68377130000.0, step = 21401 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.862\n",
      "INFO:tensorflow:loss = 144567290000.0, step = 21501 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.828\n",
      "INFO:tensorflow:loss = 64224410000.0, step = 21601 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.129\n",
      "INFO:tensorflow:loss = 51037240000.0, step = 21701 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.831\n",
      "INFO:tensorflow:loss = 70100795000.0, step = 21801 (0.367 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 237.039\n",
      "INFO:tensorflow:loss = 22504837000.0, step = 21901 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.154\n",
      "INFO:tensorflow:loss = 128138930000.0, step = 22001 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.864\n",
      "INFO:tensorflow:loss = 70618060000.0, step = 22101 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.169\n",
      "INFO:tensorflow:loss = 121092870000.0, step = 22201 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.937\n",
      "INFO:tensorflow:loss = 37394140000.0, step = 22301 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.372\n",
      "INFO:tensorflow:loss = 121583200000.0, step = 22401 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.805\n",
      "INFO:tensorflow:loss = 87782250000.0, step = 22501 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.179\n",
      "INFO:tensorflow:loss = 112585335000.0, step = 22601 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.201\n",
      "INFO:tensorflow:loss = 75443130000.0, step = 22701 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.962\n",
      "INFO:tensorflow:loss = 77240310000.0, step = 22801 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.922\n",
      "INFO:tensorflow:loss = 58301768000.0, step = 22901 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.78\n",
      "INFO:tensorflow:loss = 87703810000.0, step = 23001 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.711\n",
      "INFO:tensorflow:loss = 70836420000.0, step = 23101 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.905\n",
      "INFO:tensorflow:loss = 234573100000.0, step = 23201 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.693\n",
      "INFO:tensorflow:loss = 58351206000.0, step = 23301 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.955\n",
      "INFO:tensorflow:loss = 227722500000.0, step = 23401 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.992\n",
      "INFO:tensorflow:loss = 65009574000.0, step = 23501 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.011\n",
      "INFO:tensorflow:loss = 37359206000.0, step = 23601 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.983\n",
      "INFO:tensorflow:loss = 51915550000.0, step = 23701 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.436\n",
      "INFO:tensorflow:loss = 89304826000.0, step = 23801 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.775\n",
      "INFO:tensorflow:loss = 54808265000.0, step = 23901 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.349\n",
      "INFO:tensorflow:loss = 42460144000.0, step = 24001 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.342\n",
      "INFO:tensorflow:loss = 87248134000.0, step = 24101 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.684\n",
      "INFO:tensorflow:loss = 165599040000.0, step = 24201 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.312\n",
      "INFO:tensorflow:loss = 106677380000.0, step = 24301 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.928\n",
      "INFO:tensorflow:loss = 167596980000.0, step = 24401 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.608\n",
      "INFO:tensorflow:loss = 169818140000.0, step = 24501 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.669\n",
      "INFO:tensorflow:loss = 76602780000.0, step = 24601 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.842\n",
      "INFO:tensorflow:loss = 92152500000.0, step = 24701 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.596\n",
      "INFO:tensorflow:loss = 150880350000.0, step = 24801 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.089\n",
      "INFO:tensorflow:loss = 284122450000.0, step = 24901 (0.383 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp8uwnz2sd\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 42890190000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x2a28f79ba90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen = model.predict(predict_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp8uwnz2sd\\model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97921.93181985477"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103445.16100440205"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,final_preds)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
